{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"example3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dK0TQmS_OT_g","colab_type":"text"},"source":["# Example Transformer model for machine translation (eng to kmb)"]},{"cell_type":"markdown","metadata":{"id":"GYLYy2KkOZD3","colab_type":"text"},"source":["## Dependencies"]},{"cell_type":"code","metadata":{"id":"sJ2LEkCfO4Gx","colab_type":"code","outputId":"dc189bd8-dbcd-4426-da7e-b7c6b009ac02","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1588703302405,"user_tz":240,"elapsed":5070,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["! pip install opustools-pkg"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting opustools-pkg\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/9f/e829a0cceccc603450cd18e1ff80807b6237a88d9a8df2c0bb320796e900/opustools_pkg-0.0.52-py3-none-any.whl (80kB)\n","\r\u001b[K     |████                            | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.5MB/s \n","\u001b[?25hInstalling collected packages: opustools-pkg\n","Successfully installed opustools-pkg-0.0.52\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_m9P3UU0PAXr","colab_type":"code","outputId":"5abb0eaf-094c-4a63-a8ff-d5514cf234e6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1588703316625,"user_tz":240,"elapsed":11058,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["! git clone https://github.com/joeynmt/joeynmt.git\n","! cd joeynmt; pip3 install ."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'joeynmt'...\n","remote: Enumerating objects: 2380, done.\u001b[K\n","remote: Total 2380 (delta 0), reused 0 (delta 0), pack-reused 2380\u001b[K\n","Receiving objects: 100% (2380/2380), 2.60 MiB | 30.59 MiB/s, done.\n","Resolving deltas: 100% (1669/1669), done.\n","Processing /content/joeynmt\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.16.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (7.0.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.18.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (46.1.3)\n","Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.5.0+cu101)\n","Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (2.2.0rc4)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.3.1)\n","Collecting sacrebleu>=1.3.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n","\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n","\u001b[?25hCollecting subword-nmt\n","  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (3.2.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.10.1)\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 12.3MB/s \n","\u001b[?25hCollecting pylint\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/6e/36419ec1bd2208e157dff7fc3e565b185394c0dc4901e9e2f983cb1d4b7f/pylint-2.5.2-py3-none-any.whl (324kB)\n","\u001b[K     |████████████████████████████████| 327kB 20.7MB/s \n","\u001b[?25hRequirement already satisfied: six==1.12 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.12.0)\n","Collecting wrapt==1.11.1\n","  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (2.2.1)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (2.2.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.3.3)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.28.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.34.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.2.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.9.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.4.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.6.3)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (2.10.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (4.38.0)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt==0.0.1) (3.6.6)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.8.1)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (1.0.3)\n","Collecting mccabe<0.7,>=0.6\n","  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n","Collecting toml>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n","Collecting isort<5,>=4.2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n","\u001b[?25hCollecting astroid<=2.5,>=2.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/c9/e9c2642dfb169590fb8bdb395f9329da042ee559c2ae7c1e612a3e5f40b4/astroid-2.4.1-py3-none-any.whl (214kB)\n","\u001b[K     |████████████████████████████████| 215kB 25.0MB/s \n","\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (3.2.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (0.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (1.6.0.post3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (1.7.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2020.4.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (3.0.4)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn->joeynmt==0.0.1) (2018.9)\n","Collecting lazy-object-proxy==1.4.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/dd/b1e3407e9e6913cf178e506cd0dee818e58694d9a5cd1984e3f6a8b9a10f/lazy_object_proxy-1.4.3-cp36-cp36m-manylinux1_x86_64.whl (55kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n","\u001b[?25hCollecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n","\u001b[K     |████████████████████████████████| 747kB 28.5MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (0.2.8)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (4.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (3.1.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt==0.0.1) (0.4.8)\n","Building wheels for collected packages: joeynmt, pyyaml, wrapt\n","  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for joeynmt: filename=joeynmt-0.0.1-cp36-none-any.whl size=73768 sha256=7c12eb23b55666b4844010f16c5eacd7c43cb5d83961628a1606965f9a8bfe82\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2tut0a2b/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=d02fb53b776333bda76685a9223693065f9cdae25f7cea5d2a54e9daf8839b80\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=67428 sha256=7b91e3e5a952d100e33b77abe1093d3acb183f9cdc1eff8603563d6262f3e6c8\n","  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n","Successfully built joeynmt pyyaml wrapt\n","Installing collected packages: portalocker, sacrebleu, subword-nmt, pyyaml, mccabe, toml, isort, lazy-object-proxy, typed-ast, wrapt, astroid, pylint, joeynmt\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: wrapt 1.12.1\n","    Uninstalling wrapt-1.12.1:\n","      Successfully uninstalled wrapt-1.12.1\n","Successfully installed astroid-2.4.1 isort-4.3.21 joeynmt-0.0.1 lazy-object-proxy-1.4.3 mccabe-0.6.1 portalocker-1.7.0 pylint-2.5.2 pyyaml-5.3.1 sacrebleu-1.4.9 subword-nmt-0.3.7 toml-0.10.0 typed-ast-1.4.1 wrapt-1.11.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"akiy3TCiQgkP","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"Y4YkB1RkQiAv","colab_type":"code","colab":{}},"source":["from os import path\n","import os\n","import time\n","\n","import pandas as pd\n","import numpy as np\n","from nltk.tokenize import TreebankWordTokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61_N3-mYPRY9","colab_type":"text"},"source":["## Data Gathering"]},{"cell_type":"code","metadata":{"id":"EkW-mUdvQ1eY","colab_type":"code","colab":{}},"source":["source_language = 'en'\n","target_language = 'kmb'\n","os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\", source_language + target_language) \n","os.environ[\"src\"] = source_language \n","os.environ[\"tgt\"] = target_language"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"stPP3nXaQmK3","colab_type":"code","outputId":"a0dfc07a-ee92-4dfe-c931-527412f9ac2d","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1588703538550,"user_tz":240,"elapsed":210746,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["# JW300 data\n","! opus_read -d JW300 -s $tgt -t $src -wm moses -w jw300.$tgt jw300.$src -q\n","\n","source = []\n","target = []\n","with open('jw300.' + source_language) as f:\n","  for _, line in enumerate(f):\n","    source.append(line.strip())\n","with open('jw300.' + target_language) as f:\n","  for _, line in enumerate(f):\n","    target.append(line.strip())\n","\n","jw300_raw = []\n","for idx, line in enumerate(source):\n","  if len(line) > 2:\n","    if len(target[idx]) > 2:\n","      jw300_raw.append([line, target[idx]])\n","\n","jw300 = pd.DataFrame(jw300_raw, columns=['source_sentence', 'target_sentence'])\n","jw300.head(3)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\n","Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/en-kmb.xml.gz not found. The following files are available for downloading:\n","\n"," 920 KB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en-kmb.xml.gz\n"," 263 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en.zip\n","  10 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/kmb.zip\n","\n"," 274 MB Total size\n","./JW300_latest_xml_en-kmb.xml.gz ... 100% of 920 KB\n","./JW300_latest_xml_en.zip ... 100% of 263 MB\n","./JW300_latest_xml_kmb.zip ... 100% of 10 MB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_sentence</th>\n","      <th>target_sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Table of Contents</td>\n","      <td>Iala – mu</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>December 1 , 2010</td>\n","      <td>1 Ua Katatu Ua 2011</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Who Inhabit the Spirit Realm ?</td>\n","      <td>O Kuiala ku Diulu Kuene Muene Athu mu Nzumbi</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  source_sentence                               target_sentence\n","0               Table of Contents                                     Iala – mu\n","1               December 1 , 2010                           1 Ua Katatu Ua 2011\n","2  Who Inhabit the Spirit Realm ?  O Kuiala ku Diulu Kuene Muene Athu mu Nzumbi"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"IUJ6tYVWSXzd","colab_type":"code","outputId":"1c1291c8-d59a-47aa-ed46-3c8f6ff03b03","colab":{"base_uri":"https://localhost:8080/","height":526},"executionInfo":{"status":"ok","timestamp":1588703558724,"user_tz":240,"elapsed":3377,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["# Common test data\n","source_test_file = 'test.en-' + target_language + '.en'\n","target_test_file = 'test.en-' + target_language + '.' + target_language\n","\n","! wget https://raw.githubusercontent.com/jaderabbit/masakhane/master/jw300_utils/test/test.en-$tgt.en\n","! wget https://raw.githubusercontent.com/jaderabbit/masakhane/master/jw300_utils/test/test.en-$tgt.$tgt\n","\n","source = []\n","target = []\n","with open(source_test_file) as f:\n","  for _, line in enumerate(f):\n","    source.append(line.strip())\n","with open(target_test_file) as f:\n","  for _, line in enumerate(f):\n","    target.append(line.strip())\n","\n","! rm test.en-$tgt.en\n","! rm test.en-$tgt.$tgt\n","\n","test_raw = []\n","for idx, line in enumerate(source):\n","  if len(line) > 2:\n","    if len(target[idx]) > 2:\n","      test_raw.append([line, target[idx]])\n","\n","df_test = pd.DataFrame(test_raw, columns=['source_sentence', 'target_sentence'])\n","df_test.head(3)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2020-05-05 18:32:35--  https://raw.githubusercontent.com/jaderabbit/masakhane/master/jw300_utils/test/test.en-kmb.en\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 204945 (200K) [text/plain]\n","Saving to: ‘test.en-kmb.en’\n","\n","test.en-kmb.en      100%[===================>] 200.14K  --.-KB/s    in 0.03s   \n","\n","2020-05-05 18:32:36 (7.47 MB/s) - ‘test.en-kmb.en’ saved [204945/204945]\n","\n","--2020-05-05 18:32:36--  https://raw.githubusercontent.com/jaderabbit/masakhane/master/jw300_utils/test/test.en-kmb.kmb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 230668 (225K) [text/plain]\n","Saving to: ‘test.en-kmb.kmb’\n","\n","test.en-kmb.kmb     100%[===================>] 225.26K  --.-KB/s    in 0.03s   \n","\n","2020-05-05 18:32:36 (8.02 MB/s) - ‘test.en-kmb.kmb’ saved [230668/230668]\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_sentence</th>\n","      <th>target_sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dorcas “ abounded in good deeds and gifts of m...</td>\n","      <td>Dorka , “ [ uavudile ] jimbote ni jimola [ ja ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What will be considered in this article , and ...</td>\n","      <td>Ihi i tua - nda di longa ku mbandu íii , ni mu...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Some names in this article have been changed .</td>\n","      <td>Saí majina a a lungulula .</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     source_sentence                                    target_sentence\n","0  Dorcas “ abounded in good deeds and gifts of m...  Dorka , “ [ uavudile ] jimbote ni jimola [ ja ...\n","1  What will be considered in this article , and ...  Ihi i tua - nda di longa ku mbandu íii , ni mu...\n","2     Some names in this article have been changed .                         Saí majina a a lungulula ."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"WvH3ugvylv7v","colab_type":"text"},"source":["## Pre-processing"]},{"cell_type":"code","metadata":{"id":"LK1AiflclpdM","colab_type":"code","outputId":"b766b7a4-508b-4f27-dd64-cebccc017619","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1588703688263,"user_tz":240,"elapsed":641,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["# drop test data from common\n","df_pp = jw300[~jw300['source_sentence'].isin(df_test['source_sentence'].values)]\n","df_pp = df_pp[~df_pp['target_sentence'].isin(df_test['target_sentence'].values)]\n","\n","# remove duplicates\n","df_pp.drop_duplicates(inplace=True)\n","\n","# remove conflicting translations\n","df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n","df_pp.drop_duplicates(subset='target_sentence', inplace=True)\n","\n","# what's left in terms of number of samples?\n","len(df_pp)/len(jw300)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9117961694336439"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"iGYR610PxdGK","colab_type":"code","colab":{}},"source":["# reset the index of the training set after filtering\n","df_pp.reset_index(drop=False, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdHgU5xrmOKz","colab_type":"code","colab":{}},"source":["## Lower case the corpus\n","df_pp[\"source_sentence\"] = df_pp[\"source_sentence\"].str.lower()\n","df_pp[\"target_sentence\"] = df_pp[\"target_sentence\"].str.lower()\n","df_test[\"source_sentence\"] = df_test[\"source_sentence\"].str.lower()\n","df_test[\"target_sentence\"] = df_test[\"target_sentence\"].str.lower()\n","\n","# shuffle the training/dev data\n","df_pp = df_pp.sample(frac=1).reset_index(drop=True)\n","\n","# Do the split between dev/train\n","num_dev_patterns = 1000\n","dev = df_pp.tail(num_dev_patterns)\n","stripped = df_pp.drop(df_pp.tail(num_dev_patterns).index)\n","\n","# output the final parallel corpus files\n","with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as trg_file:\n","  for index, row in stripped.iterrows():\n","    src_file.write(row[\"source_sentence\"]+\"\\n\")\n","    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n","    \n","with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as trg_file:\n","  for index, row in dev.iterrows():\n","    src_file.write(row[\"source_sentence\"]+\"\\n\")\n","    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n","\n","with open(\"test.\"+source_language, \"w\") as src_file, open(\"test.\"+target_language, \"w\") as trg_file:\n","  for index, row in df_test.iterrows():\n","    src_file.write(row[\"source_sentence\"]+\"\\n\")\n","    trg_file.write(row[\"target_sentence\"]+\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WugPZnZ_mv5H","colab_type":"code","outputId":"16a3dc0d-93d2-4c0b-e7d1-2b50d2174e56","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"ok","timestamp":1588703746195,"user_tz":240,"elapsed":6560,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["! head train.en"],"execution_count":10,"outputs":[{"output_type":"stream","text":["it hurt him even to contemplate the deed she wanted him to commit .\n","with the help of jehovah’s spirit , your children can have strong faith .\n","god can awaken the dead , just as we can awaken a person from sleep . ​ — job 14 : 13 - 15 .\n","so whether our home will be in heaven with jesus or on a paradise earth , pentecost of the year 33 is very important to us . ​ — see endnote .\n","but remember what jehoshaphat did .\n","• what are some ways married people can let spirituality guide them ?\n","“ the father incomprehensible , the son incomprehensible , and the holy ghost incomprehensible . ” ​ — the athanasian creed , describing the trinity taught by many churches of christendom .\n","why not ? the lamp’s light is diminishing so gradually that you are not aware of it . similarly , the influences of satan’s world may cause our zeal to diminish little by little .\n","but they are not accurate .\n","joshua did not ask god what to do when the gibeonites wanted to make an agreement with him .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N9lWcwN2m0O2","colab_type":"code","outputId":"16a25214-5fb0-4be7-ebae-ef638c3bf7cb","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"ok","timestamp":1588703747359,"user_tz":240,"elapsed":7235,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["! head train.kmb"],"execution_count":11,"outputs":[{"output_type":"stream","text":["o ku xinganeka ngó ku ima ia mesenene o muhatu kuila muéne u bhanga , kia luualesa kiavulu o muxima ua zuze .\n","ni kikuatekesu kia nzumbi ikola ia jihova , o tuana tué a tena kukala ni kixikanu kia kolo .\n","( nzuá 11 : 11 - 14 ) nzambi uala ni kutena kua kuphaphumuna uoso ua fu , kála ki tuene mu balumuna mukuetu ua mu zeka . ​ — jobe 14 : 13 - 15 .\n","mu kiki , kikale se tua kingila kutunga kumoxi ni jezú ku diulu , mba mu palaízu mu ixi , o fesa ia pendekoxi ia muvu ua 33 , iala ni valolo ia dikota phala etu . ​ — tala ku disukilu dia milongi .\n","nange tu kala ni uôma uavulu .\n","• mu ukexilu uahi o jikidistá a tokala kuehela o itumu ia nzambi ku a endesa ?\n","“ ki tu tena ku tendela o tata , o mona ki tu tena ku mu tendela , o nzumbi ikôla ué ki tu tena ku i tendela . ” — o milongi ia atanasiano , ia tilindade iene mu longa mu jingeleja javulu ja kidistándade .\n","kiki kia difu ni jindunge ja mundu ua satanaji , ji tena ku tu bhangesa ku zozesa o vondadi ietu ia ku sidivila jihova .\n","maji jene , ki ja kidi kana .\n","( dialuilu 20 : 12 ) kioso o akua ngibiione kia mesenene ku ta kikutu ni josuué , muene ka soto kuijiia o vondadi ia nzambi .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eNbaZnhznC8-","colab_type":"text"},"source":["## Subword BPE Tokens"]},{"cell_type":"code","metadata":{"id":"PlSQH_bQm82c","colab_type":"code","outputId":"90063bc0-d6a3-4b79-ee93-f148a55c757f","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"ok","timestamp":1588703793794,"user_tz":240,"elapsed":36756,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["# Do BPE\n","! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n","\n","! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n","! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n","! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n","! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n","! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n","! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n","\n","# Create directory, move everyone we care about to the correct location\n","! mkdir -p $data_path\n","! cp train.* $data_path\n","! cp test.* $data_path\n","! cp dev.* $data_path\n","! cp bpe.codes.4000 $data_path\n","! ls $data_path\n","\n","# Create that vocab using build_vocab\n","! sudo chmod 777 joeynmt/scripts/build_vocab.py\n","! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n","\n","# Some output\n","! echo \"BPE Target Sentences\"\n","! tail -n 5 test.bpe.$tgt\n","! echo \"Combined BPE Vocab\"\n","! tail -n 10 joeynmt/data/en$tgt/vocab.txt"],"execution_count":12,"outputs":[{"output_type":"stream","text":["bpe.codes.4000\tdev.en\t     test.bpe.kmb  train.bpe.en   train.kmb\n","dev.bpe.en\tdev.kmb      test.en\t   train.bpe.kmb\n","dev.bpe.kmb\ttest.bpe.en  test.kmb\t   train.en\n","BPE Target Sentences\n","o ngu@@ b@@ u ya kuxikana ( tala o kaxi 12 - 14 )\n","o ka@@ pas@@ e@@ te ka kubh@@ uluka ( tala o kaxi 15 - 18 )\n","nga mono kwila o athu a xikina dingi se a mona kwila ey@@ e wa zolo mwene o bibidya , wa mu bhanga yoso i u tena phala ku a kwatekesa . ”\n","o xi@@ bhata ya nzumbi ikôla ( tala o kaxi 19 - 20 )\n","ni ki@@ kwat@@ ek@@ esu kya jihova tu tena kubh@@ ânga nê !\n","Combined BPE Vocab\n","iókio\n","sambu@@\n","mulang@@\n","ízu\n","iiale\n","langu@@\n","njin@@\n","kobo\n","fuxi\n","c.@@\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mox2nEPXnnOe","colab_type":"text"},"source":["## JoeyNMT Config"]},{"cell_type":"code","metadata":{"id":"ugHbYjQPnNo4","colab_type":"code","colab":{}},"source":["# This creates the config file for our JoeyNMT system. \n","name = '%s%s' % (source_language, target_language)\n","\n","config = \"\"\"\n","name: \"{name}_transformer\"\n","\n","data:\n","    src: \"{source_language}\"\n","    trg: \"{target_language}\"\n","    train: \"data/{name}/train.bpe\"\n","    dev:   \"data/{name}/dev.bpe\"\n","    test:  \"data/{name}/test.bpe\"\n","    level: \"bpe\"\n","    lowercase: False\n","    max_sent_length: 100\n","    src_vocab: \"data/{name}/vocab.txt\"\n","    trg_vocab: \"data/{name}/vocab.txt\"\n","\n","testing:\n","    beam_size: 5\n","    alpha: 1.0\n","\n","training:\n","    #load_model: \"models/{name}_transformer/12000.ckpt\" # if given, load a pre-trained model from this checkpoint\n","    random_seed: 42\n","    optimizer: \"adam\"\n","    normalization: \"tokens\"\n","    adam_betas: [0.9, 0.999] \n","    scheduling: \"noam\"            # Try switching from plateau to Noam scheduling\n","    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n","    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n","    patience: 8\n","    decrease_factor: 0.7\n","    loss: \"crossentropy\"\n","    learning_rate: 0.0002\n","    learning_rate_min: 0.00000001\n","    weight_decay: 0.0\n","    label_smoothing: 0.1\n","    batch_size: 4096\n","    batch_type: \"token\"\n","    eval_batch_size: 3600\n","    eval_batch_type: \"token\"\n","    batch_multiplier: 1\n","    early_stopping_metric: \"eval_metric\" # \"ppl\"\n","    epochs: 40\n","    validation_freq: 2000\n","    logging_freq: 200\n","    eval_metric: \"bleu\"\n","    model_dir: \"models/{name}_transformer\"\n","    overwrite: True\n","    shuffle: True\n","    use_cuda: True\n","    max_output_length: 100\n","    print_valid_sents: [0, 1, 2, 3]\n","    keep_last_ckpts: 3\n","\n","model:\n","    initializer: \"xavier\"\n","    bias_initializer: \"zeros\"\n","    init_gain: 1.0\n","    embed_initializer: \"xavier\"\n","    embed_init_gain: 1.0\n","    tied_embeddings: True\n","    tied_softmax: True\n","    encoder:\n","        type: \"transformer\"\n","        num_layers: 6\n","        num_heads: 8\n","        embeddings:\n","            embedding_dim: 512\n","            scale: True\n","            dropout: 0.\n","        # typically ff_size = 4 x hidden_size\n","        hidden_size: 512\n","        ff_size: 2048\n","        dropout: 0.3\n","    decoder:\n","        type: \"transformer\"\n","        num_layers: 6\n","        num_heads: 8\n","        embeddings:\n","            embedding_dim: 512\n","            scale: True\n","            dropout: 0.\n","        # typically ff_size = 4 x hidden_size\n","        hidden_size: 512\n","        ff_size: 2048\n","        dropout: 0.3\n","\"\"\".format(name=name, source_language=source_language, target_language=target_language)\n","with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n","    f.write(config)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eNQ_9LO4n04W","colab_type":"text"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"hWwNavEHnxs8","colab_type":"code","outputId":"00cb5e7c-d18e-45fb-c8f8-9d93feb51a7a","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1588704383313,"user_tz":240,"elapsed":534691,"user":{"displayName":"Daniel Whitenack","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjAksu_ElVnuka7KuOLHjyaXiy4v9BA2P1AqagM2w=s64","userId":"15195746376658990804"}}},"source":["!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2020-05-05 18:37:35,212 Hello! This is Joey-NMT.\n","2020-05-05 18:37:35.336316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-05-05 18:37:36,615 Total params: 46259200\n","2020-05-05 18:37:36,616 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight']\n","2020-05-05 18:37:52,511 cfg.name                           : enkmb_transformer\n","2020-05-05 18:37:52,511 cfg.data.src                       : en\n","2020-05-05 18:37:52,512 cfg.data.trg                       : kmb\n","2020-05-05 18:37:52,512 cfg.data.train                     : data/enkmb/train.bpe\n","2020-05-05 18:37:52,512 cfg.data.dev                       : data/enkmb/dev.bpe\n","2020-05-05 18:37:52,512 cfg.data.test                      : data/enkmb/test.bpe\n","2020-05-05 18:37:52,512 cfg.data.level                     : bpe\n","2020-05-05 18:37:52,512 cfg.data.lowercase                 : False\n","2020-05-05 18:37:52,512 cfg.data.max_sent_length           : 100\n","2020-05-05 18:37:52,512 cfg.data.src_vocab                 : data/enkmb/vocab.txt\n","2020-05-05 18:37:52,512 cfg.data.trg_vocab                 : data/enkmb/vocab.txt\n","2020-05-05 18:37:52,512 cfg.testing.beam_size              : 5\n","2020-05-05 18:37:52,512 cfg.testing.alpha                  : 1.0\n","2020-05-05 18:37:52,512 cfg.training.random_seed           : 42\n","2020-05-05 18:37:52,512 cfg.training.optimizer             : adam\n","2020-05-05 18:37:52,512 cfg.training.normalization         : tokens\n","2020-05-05 18:37:52,512 cfg.training.adam_betas            : [0.9, 0.999]\n","2020-05-05 18:37:52,512 cfg.training.scheduling            : noam\n","2020-05-05 18:37:52,512 cfg.training.learning_rate_factor  : 0.5\n","2020-05-05 18:37:52,512 cfg.training.learning_rate_warmup  : 1000\n","2020-05-05 18:37:52,513 cfg.training.patience              : 8\n","2020-05-05 18:37:52,513 cfg.training.decrease_factor       : 0.7\n","2020-05-05 18:37:52,513 cfg.training.loss                  : crossentropy\n","2020-05-05 18:37:52,513 cfg.training.learning_rate         : 0.0002\n","2020-05-05 18:37:52,513 cfg.training.learning_rate_min     : 1e-08\n","2020-05-05 18:37:52,513 cfg.training.weight_decay          : 0.0\n","2020-05-05 18:37:52,513 cfg.training.label_smoothing       : 0.1\n","2020-05-05 18:37:52,513 cfg.training.batch_size            : 4096\n","2020-05-05 18:37:52,513 cfg.training.batch_type            : token\n","2020-05-05 18:37:52,513 cfg.training.eval_batch_size       : 3600\n","2020-05-05 18:37:52,513 cfg.training.eval_batch_type       : token\n","2020-05-05 18:37:52,513 cfg.training.batch_multiplier      : 1\n","2020-05-05 18:37:52,513 cfg.training.early_stopping_metric : eval_metric\n","2020-05-05 18:37:52,513 cfg.training.epochs                : 40\n","2020-05-05 18:37:52,513 cfg.training.validation_freq       : 2000\n","2020-05-05 18:37:52,513 cfg.training.logging_freq          : 200\n","2020-05-05 18:37:52,513 cfg.training.eval_metric           : bleu\n","2020-05-05 18:37:52,513 cfg.training.model_dir             : models/enkmb_transformer\n","2020-05-05 18:37:52,513 cfg.training.overwrite             : True\n","2020-05-05 18:37:52,513 cfg.training.shuffle               : True\n","2020-05-05 18:37:52,514 cfg.training.use_cuda              : True\n","2020-05-05 18:37:52,514 cfg.training.max_output_length     : 100\n","2020-05-05 18:37:52,514 cfg.training.print_valid_sents     : [0, 1, 2, 3]\n","2020-05-05 18:37:52,514 cfg.training.keep_last_ckpts       : 3\n","2020-05-05 18:37:52,514 cfg.model.initializer              : xavier\n","2020-05-05 18:37:52,514 cfg.model.bias_initializer         : zeros\n","2020-05-05 18:37:52,514 cfg.model.init_gain                : 1.0\n","2020-05-05 18:37:52,514 cfg.model.embed_initializer        : xavier\n","2020-05-05 18:37:52,514 cfg.model.embed_init_gain          : 1.0\n","2020-05-05 18:37:52,514 cfg.model.tied_embeddings          : True\n","2020-05-05 18:37:52,514 cfg.model.tied_softmax             : True\n","2020-05-05 18:37:52,514 cfg.model.encoder.type             : transformer\n","2020-05-05 18:37:52,514 cfg.model.encoder.num_layers       : 6\n","2020-05-05 18:37:52,514 cfg.model.encoder.num_heads        : 8\n","2020-05-05 18:37:52,514 cfg.model.encoder.embeddings.embedding_dim : 512\n","2020-05-05 18:37:52,514 cfg.model.encoder.embeddings.scale : True\n","2020-05-05 18:37:52,514 cfg.model.encoder.embeddings.dropout : 0.0\n","2020-05-05 18:37:52,514 cfg.model.encoder.hidden_size      : 512\n","2020-05-05 18:37:52,514 cfg.model.encoder.ff_size          : 2048\n","2020-05-05 18:37:52,515 cfg.model.encoder.dropout          : 0.3\n","2020-05-05 18:37:52,515 cfg.model.decoder.type             : transformer\n","2020-05-05 18:37:52,515 cfg.model.decoder.num_layers       : 6\n","2020-05-05 18:37:52,515 cfg.model.decoder.num_heads        : 8\n","2020-05-05 18:37:52,515 cfg.model.decoder.embeddings.embedding_dim : 512\n","2020-05-05 18:37:52,515 cfg.model.decoder.embeddings.scale : True\n","2020-05-05 18:37:52,515 cfg.model.decoder.embeddings.dropout : 0.0\n","2020-05-05 18:37:52,515 cfg.model.decoder.hidden_size      : 512\n","2020-05-05 18:37:52,515 cfg.model.decoder.ff_size          : 2048\n","2020-05-05 18:37:52,515 cfg.model.decoder.dropout          : 0.3\n","2020-05-05 18:37:52,515 Data set sizes: \n","\ttrain 87564,\n","\tvalid 1000,\n","\ttest 2693\n","2020-05-05 18:37:52,515 First training example:\n","\t[SRC] it hur@@ t him even to con@@ temp@@ l@@ ate the de@@ ed she wanted him to comm@@ it .\n","\t[TRG] o ku xinganeka ngó ku ima ia mesenene o muhatu kuila muéne u bhanga , kia luualesa kiavulu o muxima ua zuze .\n","2020-05-05 18:37:52,515 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) o (7) ku (8) mu (9) the\n","2020-05-05 18:37:52,516 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) o (7) ku (8) mu (9) the\n","2020-05-05 18:37:52,516 Number of Src words (types): 4138\n","2020-05-05 18:37:52,516 Number of Trg words (types): 4138\n","2020-05-05 18:37:52,516 Model(\n","\tencoder=TransformerEncoder(num_layers=6, num_heads=8),\n","\tdecoder=TransformerDecoder(num_layers=6, num_heads=8),\n","\tsrc_embed=Embeddings(embedding_dim=512, vocab_size=4138),\n","\ttrg_embed=Embeddings(embedding_dim=512, vocab_size=4138))\n","2020-05-05 18:37:52,519 EPOCH 1\n","/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero(Tensor input, *, Tensor out)\n","Consider using one of the following signatures instead:\n","\tnonzero(Tensor input, *, bool as_tuple)\n","2020-05-05 18:38:34,663 Epoch   1 Step:      200 Batch Loss:     5.188022 Tokens per Sec:    10152, Lr: 0.000140\n","2020-05-05 18:39:16,323 Epoch   1 Step:      400 Batch Loss:     3.753244 Tokens per Sec:    10366, Lr: 0.000280\n","2020-05-05 18:39:57,968 Epoch   1 Step:      600 Batch Loss:     3.269442 Tokens per Sec:    10329, Lr: 0.000419\n","2020-05-05 18:40:39,441 Epoch   1 Step:      800 Batch Loss:     3.061397 Tokens per Sec:    10219, Lr: 0.000559\n","2020-05-05 18:41:20,636 Epoch   1 Step:     1000 Batch Loss:     2.718370 Tokens per Sec:    10213, Lr: 0.000699\n","2020-05-05 18:41:24,738 Epoch   1: total training loss 4005.32\n","2020-05-05 18:41:24,738 EPOCH 2\n","2020-05-05 18:42:02,082 Epoch   2 Step:     1200 Batch Loss:     2.782317 Tokens per Sec:    10124, Lr: 0.000638\n","2020-05-05 18:42:43,575 Epoch   2 Step:     1400 Batch Loss:     2.369255 Tokens per Sec:    10154, Lr: 0.000591\n","2020-05-05 18:43:25,376 Epoch   2 Step:     1600 Batch Loss:     2.434922 Tokens per Sec:    10261, Lr: 0.000552\n","2020-05-05 18:44:06,949 Epoch   2 Step:     1800 Batch Loss:     2.785870 Tokens per Sec:    10244, Lr: 0.000521\n","2020-05-05 18:44:48,759 Epoch   2 Step:     2000 Batch Loss:     2.262645 Tokens per Sec:    10227, Lr: 0.000494\n","2020-05-05 18:45:19,528 Hooray! New best validation result [eval_metric]!\n","2020-05-05 18:45:19,529 Saving new checkpoint.\n","2020-05-05 18:45:21,143 Example #0\n","2020-05-05 18:45:21,144 \tSource:     second , use god’s word and publications from the faithful slave to help you see the difference between “ sadness of the world ” and “ sadness in a godly way , ” that is , genuine repentance .\n","2020-05-05 18:45:21,144 \tReference:  ( 1 jisobha 3 : 9 ) kia kaiiadi , tanga o mak’â nzambi ni madivulu ene mu tu tumikisa o kimbadi kia fiiele , phala ku kukuatekesa kutungula ‘ o kudiela kua makutu ’ mu ‘ kudiela kua kidi . ’\n","2020-05-05 18:45:21,144 \tHypothesis: mu ku bhita kithangana , o bibidia i kuatekesa o jikidistá ku ‘ kaiela o itendelesu ia nzambi , ’ mu ku bhanga o vondadi ia ku bhanga o vondadi ia ku bhanga o vondadi ia ku bhanga o vondadi ia ku bhanga .\n","2020-05-05 18:45:21,144 Example #1\n","2020-05-05 18:45:21,144 \tSource:     “ i can’t remember receiving any commendation or affection from her . ”\n","2020-05-05 18:45:21,144 \tReference:  muéne kexile mu londekesa kuila ua ngi zolele . ”\n","2020-05-05 18:45:21,144 \tHypothesis: “ nga mono kuila , nga kexile mu zuela ni muxima uoso , ni ku mu kuatekesa . ”\n","2020-05-05 18:45:21,144 Example #2\n","2020-05-05 18:45:21,144 \tSource:     what does god’s love mean to you ?\n","2020-05-05 18:45:21,145 \tReference:  ihi ilombolola o henda ia nzambi phala eie ?\n","2020-05-05 18:45:21,145 \tHypothesis: ihi ilombolola o henda ia nzambi ?\n","2020-05-05 18:45:21,145 Example #3\n","2020-05-05 18:45:21,145 \tSource:     but john the baptizer had already forewarned them that if jehovah wished to do so , he could raise up children to abraham from the very stones . ​ — luke 3 : 8 .\n","2020-05-05 18:45:21,145 \tReference:  3 : 8 .\n","2020-05-05 18:45:21,145 \tHypothesis: maji nzuá ua kexile mu zuela kuila , o tuana tueji kala ni tuana tué , se a mu tangela kuila , jihova ua a solo phala ku mu bhana o tuana tuê . ​ — luka 13 : 13 .\n","2020-05-05 18:45:21,145 Validation result (greedy) at epoch   2, step     2000: bleu:  10.47, loss: 61598.0820, ppl:  11.0014, duration: 32.3856s\n","2020-05-05 18:45:30,461 Epoch   2: total training loss 2723.61\n","2020-05-05 18:45:30,461 EPOCH 3\n","2020-05-05 18:46:03,374 Epoch   3 Step:     2200 Batch Loss:     2.076271 Tokens per Sec:    10237, Lr: 0.000471\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/content/joeynmt/joeynmt/__main__.py\", line 41, in <module>\n","    main()\n","  File \"/content/joeynmt/joeynmt/__main__.py\", line 29, in main\n","    train(cfg_file=args.config_path)\n","  File \"/content/joeynmt/joeynmt/training.py\", line 650, in train\n","    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)\n","  File \"/content/joeynmt/joeynmt/training.py\", line 326, in train_and_validate\n","    batch, update=update, count=count)\n","  File \"/content/joeynmt/joeynmt/training.py\", line 500, in _train_batch\n","    norm_batch_loss.backward()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 198, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 100, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EgjqnSBFn2eh","colab_type":"code","outputId":"2d516f75-cac4-43ff-fbc8-27b40f508ea4","colab":{"base_uri":"https://localhost:8080/","height":260}},"source":["! cat joeynmt/models/enkmb_transformer/validations.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Steps: 2000\tLoss: 47097.83984\tPPL: 8.26328\tbleu: 14.85684\tLR: 0.00049411\t*\n","Steps: 4000\tLoss: 39856.20312\tPPL: 5.97219\tbleu: 20.91001\tLR: 0.00034939\t*\n","Steps: 6000\tLoss: 37121.82812\tPPL: 5.28307\tbleu: 23.80892\tLR: 0.00028527\t*\n","Steps: 8000\tLoss: 35674.49609\tPPL: 4.95110\tbleu: 25.00066\tLR: 0.00024705\t*\n","Steps: 10000\tLoss: 34720.73828\tPPL: 4.74383\tbleu: 26.10309\tLR: 0.00022097\t*\n","Steps: 12000\tLoss: 34417.08594\tPPL: 4.67967\tbleu: 26.15923\tLR: 0.00020172\t*\n","Steps: 14000\tLoss: 34284.73047\tPPL: 4.65198\tbleu: 27.20639\tLR: 0.00018675\t*\n","Steps: 16000\tLoss: 34352.42969\tPPL: 4.66613\tbleu: 27.29388\tLR: 0.00017469\t*\n","Steps: 18000\tLoss: 34467.03906\tPPL: 4.69017\tbleu: 27.56135\tLR: 0.00016470\t*\n","Steps: 20000\tLoss: 34512.35938\tPPL: 4.69971\tbleu: 27.82828\tLR: 0.00015625\t*\n","Steps: 22000\tLoss: 34950.40234\tPPL: 4.79293\tbleu: 27.65960\tLR: 0.00014898\t\n","Steps: 24000\tLoss: 35239.23828\tPPL: 4.85541\tbleu: 27.80829\tLR: 0.00014264\t\n","Steps: 26000\tLoss: 35323.68750\tPPL: 4.87383\tbleu: 28.57189\tLR: 0.00013704\t*\n","Steps: 28000\tLoss: 35734.37109\tPPL: 4.96441\tbleu: 27.94465\tLR: 0.00013206\t\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lWQd7EtrKLyZ","colab_type":"text"},"source":["# Evaluate the model on the test set"]},{"cell_type":"code","metadata":{"id":"9NOP9uXVsMDi","colab_type":"code","outputId":"f649ef87-c285-4c4b-b7cb-f44c2251781d","colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["! cd joeynmt; python3 -m joeynmt test models/enkmb_transformer/config.yaml "],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-02-04 22:38:57,549 Hello! This is Joey-NMT.\n","2020-02-04 22:39:38,351  dev bleu:  28.81 [Beam search decoding with beam size = 5 and alpha = 1.0]\n","2020-02-04 22:41:09,183 test bleu:  32.76 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nS2NiVSMX5bB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}